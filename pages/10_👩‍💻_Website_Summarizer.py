"""
main.py
"""
import os
from typing import List
from dotenv import load_dotenv

from langchain.callbacks import get_openai_callback
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.schema import (HumanMessage, AIMessage)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Qdrant
from langchain.embeddings.openai import OpenAIEmbeddings
import streamlit as st
import openai
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()
# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = os.environ["OPENAI_API_KEY"]

# Title
st.title("streamlit sample")

# side
st.sidebar.title("Options")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
user_select_model = st.sidebar.radio("Choose a model:", ["gpt-3.5-turbo"])

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
# clear_button = st.sidebar.button("Clear Conversation", key="clear")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
# åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
user_select_temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.1)

# å®šæ•°å®šç¾©
USER_NAME = "user"
ASSISTANT_NAME = "assistant"
COLLECTION_NAME = "my_collection"
SUMMARY_CONTENT_LIMIT = 400

def initialize():
    """
    åˆæœŸè¡¨ç¤ºå‡¦ç†
    """

    # st.set_page_config(
    #     page_title="streamlit sample",
    #     page_icon="ğŸ¤—"
    # )
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒURLå½¢å¼ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    # if validate_url(user_message):
    #     content = get_content(user_message)
    #     user_message = build_web_summary_prompt(content)

    # chat_response = openai.ChatCompletion.create(
    #     model=user_select_model,
    #     temperature=user_select_temperature,
    #     messages=[
    #         {"role": "user", "content": user_message},
    #     ],
    #     stream=True,
    # )

def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            # SystemMessage(content="You are a helpful assistant.")
        ]
        st.session_state.costs = []


def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"

    return ChatOpenAI(temperature=0, model_name=model_name)


def get_url_input():
    url = st.text_input("URL: ", key="input")
    return url

def get_content(url: str):
    """
    Webãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
    Args:
        ulr (str): URL
    """
    try:
        res = requests.get(url)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        if soup.main:
            return soup.main.get_text()
        elif soup.article:
            return soup.article.get_text()
        else:
            return soup.body.get_text()
    except:
        st.write('something wrong')
        return None

def build_web_summary_prompt(content: str):
    """
    Webã‚µã‚¤ãƒˆè¦ç´„ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    Args:
        content (str): Webãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """
    return f"""ä»¥ä¸‹ã¯ã¨ã‚ã‚‹Webãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã‚ã‚‹ã€‚å†…å®¹ã‚’{SUMMARY_CONTENT_LIMIT}ç¨‹åº¦ã§ã‚ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚

========

{content[:1000]}

========

æ—¥æœ¬èªã§æ›¸ã„ã¦ã­ï¼
"""

def validate_url(url: str):
    """
    URLãƒã‚§ãƒƒã‚¯
    Args:
        url (str): URL
    """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False

def page_chat(openai_api_key):
    """_summary_
    ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸
    """

    st.title("Chat")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¢ãƒ‡ãƒ«é¸æŠ
    user_select_model = st.sidebar.radio("Choose a model:", ["gpt-3.5-turbo-16k", "gpt-3.5-turbo"])
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šä¼šè©±å±¥æ­´å‰Šé™¤
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼štemperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠ
    user_select_temperature = st.sidebar.slider(
        "Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.1)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒãªã„å ´åˆã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message(ASSISTANT_NAME):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message(USER_NAME):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")

    if user_message := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
        st.session_state.messages.append(HumanMessage(content=user_message))
        with st.chat_message(USER_NAME):
            st.markdown(user_message)
        # OpenAI APIé€šä¿¡ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            model=user_select_model,
            temperature=user_select_temperature)
        with st.spinner("ChatGPT is typing ..."):
            response = llm(st.session_state.messages)
        st.session_state.messages.append(AIMessage(content=response.content))
        with st.chat_message(ASSISTANT_NAME):
            st.markdown(response.content)

def get_answer(llm, messages):
    with get_openai_callback() as cb:
        answer = llm(messages)
    return answer.content, cb.total_cost

def main():
    initialize()

    llm = select_model()
    init_messages()

    container = st.container()
    response_container = st.container()

    with container:
        url = get_url_input()
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.write('Please input valid url')
            answer = None
        else:
            content = get_content(url)
            if content:
                prompt = build_web_summary_prompt(content)
                st.session_state.messages.append(HumanMessage(content=prompt))
                with st.spinner("ChatGPT is typing ..."):
                    answer, cost = get_answer(llm, st.session_state.messages)
                st.session_state.costs.append(cost)
            else:
                answer = None

    if answer:
        with response_container:
            st.markdown("## Summary")
            st.write(answer)
            st.markdown("---")
            st.markdown("## Original Text")
            st.write(content)

    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")

if __name__ == '__main__':
    main()
